{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "OfumiRdvLuFc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c3f5ee65-6bfa-4e5a-c1cd-a1547ec982f1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "!pip install scikit-learn==1.5.0\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.preprocessing import StandardScaler, OneHotEncoder, MinMaxScaler, RobustScaler\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.pipeline import Pipeline, FunctionTransformer\n",
        "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "import lightgbm as lgb\n",
        "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
        "from sklearn import tree\n",
        "from sklearn import linear_model\n",
        "from sklearn.linear_model import Ridge, Lasso, SGDRegressor\n",
        "import lightgbm as lgb\n",
        "from sklearn.gaussian_process import GaussianProcessRegressor\n",
        "from sklearn.gaussian_process.kernels import RBF, ConstantKernel as C\n",
        "from sklearn.cross_decomposition import PLSRegression, PLSCanonical, CCA\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.experimental import enable_hist_gradient_boosting\n",
        "from sklearn.ensemble import HistGradientBoostingRegressor\n",
        "!pip show scikit-learn\n",
        "import pickle"
      ],
      "metadata": {
        "id": "71Ze_keiMWfR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fedd1a2f-fc51-4180-832b-42de3b01e0dc"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting scikit-learn==1.5.0\n",
            "  Downloading scikit_learn-1.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (11 kB)\n",
            "Requirement already satisfied: numpy>=1.19.5 in /usr/local/lib/python3.10/dist-packages (from scikit-learn==1.5.0) (1.26.4)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn==1.5.0) (1.13.1)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn==1.5.0) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn==1.5.0) (3.5.0)\n",
            "Downloading scikit_learn-1.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (13.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.3/13.3 MB\u001b[0m \u001b[31m28.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: scikit-learn\n",
            "  Attempting uninstall: scikit-learn\n",
            "    Found existing installation: scikit-learn 1.3.2\n",
            "    Uninstalling scikit-learn-1.3.2:\n",
            "      Successfully uninstalled scikit-learn-1.3.2\n",
            "Successfully installed scikit-learn-1.5.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/dask/dataframe/__init__.py:42: FutureWarning: \n",
            "Dask dataframe query planning is disabled because dask-expr is not installed.\n",
            "\n",
            "You can install it with `pip install dask[dataframe]` or `conda install dask`.\n",
            "This will raise in a future version.\n",
            "\n",
            "  warnings.warn(msg, FutureWarning)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/experimental/enable_hist_gradient_boosting.py:16: UserWarning: Since version 1.0, it is not needed to import enable_hist_gradient_boosting anymore. HistGradientBoostingClassifier and HistGradientBoostingRegressor are now stable and can be normally imported from sklearn.ensemble.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Name: scikit-learn\n",
            "Version: 1.5.0\n",
            "Summary: A set of python modules for machine learning and data mining\n",
            "Home-page: https://scikit-learn.org\n",
            "Author: \n",
            "Author-email: \n",
            "License: new BSD\n",
            "Location: /usr/local/lib/python3.10/dist-packages\n",
            "Requires: joblib, numpy, scipy, threadpoolctl\n",
            "Required-by: bigframes, fastai, imbalanced-learn, librosa, mlxtend, sklearn-pandas, yellowbrick\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Data loading and preprocessing\n",
        "\n",
        "filepath = '/content/drive/My Drive/CSV/final_results.csv'\n",
        "data_df = pd.read_csv(filepath)\n",
        "#remove useless data\n",
        "data_df.drop(columns=[\"NCT Numbers\", 'Top 5 Side Effects Female', 'Top 5 Side Effects Male', 'Most relevant studies'], inplace=True)\n",
        "\n",
        "pd.set_option('display.max_columns',None)  # Show all columns\n",
        "pd.set_option('display.expand_frame_repr', False)  # Do not wrap columns\n",
        "print(data_df)"
      ],
      "metadata": {
        "id": "mTVDr21RM2S6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "283d778f-b92c-47a3-d3ee-5df5396966b2"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "             Drug             Indication  Total Female Reports  Total Male Reports  Percentage Female Reports  Percentage Male Reports  Percentage Serious Female Reports  Percentage Serious Male Reports  Num Studies  Total females in studies  Total males in studies  Female proportion in studies  Male proportion in studies  Number of participants in most relevant studies  Number of female participants in most relevant studies  Number of male participants in most relevant studies  Proportion of females in most relevant studies  Proportion of males in most relevant studies  Prevalence Men  Prevalence Women  Prevalence Both Genders\n",
            "0     CLOPIDOGREL  MYOCARDIAL INFARCTION                   178                 318                      35.89                    64.11                              96.63                            88.05         64.0                    6132.0                 17162.0                         26.32                       73.68                                            22214                                               5760                                                   16454                                          25.929594                                     74.070406        2.670455          1.035000                 1.809545\n",
            "1         HEPARIN  MYOCARDIAL INFARCTION                    32                  33                      49.23                    50.77                             100.00                            96.97         24.0                    2858.0                  8468.0                         25.23                       74.77                                            11170                                               2826                                                    8344                                          25.299910                                     74.700090        2.670455          1.035000                 1.809545\n",
            "2    TENECTEPLASE  MYOCARDIAL INFARCTION                    57                  37                      60.64                    39.36                              98.25                            97.30          9.0                     822.0                  3052.0                         21.22                       78.78                                             3874                                                822                                                    3052                                          21.218379                                     78.781621        2.670455          1.035000                 1.809545\n",
            "3    ATORVASTATIN  MYOCARDIAL INFARCTION                   298                 182                      62.08                    37.92                              97.32                            90.66         24.0                      62.0                    64.0                         49.21                       50.79                                              126                                                 62                                                      64                                          49.206349                                     50.793651        2.670455          1.035000                 1.809545\n",
            "4         ASPIRIN  MYOCARDIAL INFARCTION                   369                 433                      46.01                    53.99                              98.92                            92.15         42.0                   80206.0                   817.0                         98.99                        1.01                                            80246                                              79888                                                     358                                          99.553872                                      0.446128        2.670455          1.035000                 1.809545\n",
            "..            ...                    ...                   ...                 ...                        ...                      ...                                ...                              ...          ...                       ...                     ...                           ...                         ...                                              ...                                                ...                                                     ...                                                ...                                           ...             ...               ...                      ...\n",
            "297    ROPINIROLE            PARKINSON'S                    45                 193                      18.91                    81.09                              46.67                            88.60          7.0                     646.0                   601.0                         51.80                       48.20                                             1247                                                646                                                     601                                          51.804330                                     48.195670        0.521111          0.336667                 0.418333\n",
            "298    TOPIRAMATE            PARKINSON'S                    30                   0                     100.00                     0.00                             100.00                            -1.00          3.0                      31.0                    56.0                         35.63                       64.37                                               87                                                 31                                                      56                                          35.632184                                     64.367816        0.521111          0.336667                 0.418333\n",
            "299    ROTIGOTINE            PARKINSON'S                   114                 222                      33.93                    66.07                              83.33                            97.75         31.0                    2742.0                  4257.0                         39.18                       60.82                                             2486                                               1052                                                    1434                                          42.316975                                     57.683025        0.521111          0.336667                 0.418333\n",
            "300   APOMORPHINE            PARKINSON'S                   135                 249                      35.16                    64.84                              73.33                           100.00         14.0                     146.0                   288.0                         33.64                       66.36                                              434                                                146                                                     288                                          33.640553                                     66.359447        0.521111          0.336667                 0.418333\n",
            "301   BENSERAZIDE            PARKINSON'S                     9                  55                      14.06                    85.94                             100.00                            98.18          4.0                    1052.0                  1110.0                         48.66                       51.34                                             2162                                               1052                                                    1110                                          48.658649                                     51.341351        0.521111          0.336667                 0.418333\n",
            "\n",
            "[302 rows x 21 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# data normalization\n",
        "\n",
        "def divide_by_100(x):\n",
        "    return x/100\n",
        "\n",
        "divide_transformer = FunctionTransformer(divide_by_100)\n",
        "# data normalization\n",
        "preprocessor = ColumnTransformer(\n",
        "    transformers=[\n",
        "        # OneHotEncode 'Indication'\n",
        "        ('categorical', OneHotEncoder(), ['Indication']),\n",
        "\n",
        "        # Scale percentages (assuming they are already in the range [0, 1])\n",
        "        ('percentages', divide_transformer, [\n",
        "            'Percentage Female Reports',\n",
        "            'Percentage Male Reports',\n",
        "            'Female proportion in studies',\n",
        "            'Male proportion in studies',\n",
        "            'Proportion of females in most relevant studies',\n",
        "            'Proportion of males in most relevant studies'\n",
        "        ]),\n",
        "\n",
        "        # Scale 'Prevalence Men' and 'Prevalence Women' using RobustScaler\n",
        "        # ('prevalence', RobustScaler(), ['Prevalence Men', 'Prevalence Women', 'Prevalence Both Genders']),\n",
        "\n",
        "        # Scale 'Num Studies' using MinMaxScaler\n",
        "        ('num', MinMaxScaler(), ['Num Studies', 'Total females in studies','Total males in studies', 'Number of participants in most relevant studies','Number of female participants in most relevant studies', 'Number of male participants in most relevant studies'])\n",
        "    ]\n",
        ")\n",
        "\n",
        "transformed_data = preprocessor.fit_transform(data_df)\n",
        "\n",
        "# Get the transformed column names\n",
        "transformed_columns = (\n",
        "    preprocessor.transformers_[0][1].get_feature_names_out(['Indication']).tolist() +\n",
        "    [\n",
        "        'Percentage Female Reports',\n",
        "        'Percentage Male Reports',\n",
        "        'Total females in studies',\n",
        "        'Total males in studies',\n",
        "        'Female proportion in studies',\n",
        "        'Male proportion in studies',\n",
        "        'Proportion of females in most relevant studies',\n",
        "        'Proportion of males in most relevant studies',\n",
        "        # 'Prevalence Men',\n",
        "        # 'Prevalence Women',\n",
        "        # 'Prevalence Both Genders',\n",
        "        'Num Studies',\n",
        "        'Number of participants in most relevant studies',\n",
        "        'Number of female participants in most relevant studies',\n",
        "        'Number of male participants in most relevant studies'\n",
        "    ]\n",
        ")\n",
        "\n",
        "\n",
        "# Convert the transformed data to a DataFrame\n",
        "transformed_df = pd.DataFrame(transformed_data, columns=transformed_columns)\n",
        "print(transformed_df)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5lZA_v4Rp8hq",
        "outputId": "6a1dbdaa-ebe0-4348-81fb-83cb37964e87"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     Indication_ASTHMA  Indication_CHRONIC OBSTRUCTIVE PULMONARY DISEASE  Indication_DEMENTIA  Indication_DIABETES  Indication_EPILEPSY  Indication_HEART FAILURE  Indication_HYPERTENSION  Indication_ISCHEMIC HEART DISEASE  Indication_MULTIPLE SCLEROSIS  Indication_MYOCARDIAL INFARCTION  Indication_PARKINSON'S  Indication_SCHIZOPHRENIA  Indication_STROKE  Percentage Female Reports  Percentage Male Reports  Total females in studies  Total males in studies  Female proportion in studies  Male proportion in studies  Proportion of females in most relevant studies  Proportion of males in most relevant studies  Num Studies  Number of participants in most relevant studies  Number of female participants in most relevant studies  Number of male participants in most relevant studies\n",
            "0                  0.0                                               0.0                  0.0                  0.0                  0.0                       0.0                      0.0                                0.0                            0.0                               1.0                     0.0                       0.0                0.0                     0.3589                   0.6411                    0.2632                  0.7368                      0.259296                    0.740704                                        0.069714                                      0.002367     0.007915                                         0.004666                                           0.002224                                                0.007589   \n",
            "1                  0.0                                               0.0                  0.0                  0.0                  0.0                       0.0                      0.0                                0.0                            0.0                               1.0                     0.0                       0.0                0.0                     0.4923                   0.5077                    0.2523                  0.7477                      0.252999                    0.747001                                        0.024000                                      0.001103     0.003906                                         0.002344                                           0.001090                                                0.003848   \n",
            "2                  0.0                                               0.0                  0.0                  0.0                  0.0                       0.0                      0.0                                0.0                            0.0                               1.0                     0.0                       0.0                0.0                     0.6064                   0.3936                    0.2122                  0.7878                      0.212184                    0.787816                                        0.006857                                      0.000316     0.001408                                         0.000810                                           0.000316                                                0.001408   \n",
            "3                  0.0                                               0.0                  0.0                  0.0                  0.0                       0.0                      0.0                                0.0                            0.0                               1.0                     0.0                       0.0                0.0                     0.6208                   0.3792                    0.4921                  0.5079                      0.492063                    0.507937                                        0.024000                                      0.000022     0.000030                                         0.000022                                           0.000022                                                0.000030   \n",
            "4                  0.0                                               0.0                  0.0                  0.0                  0.0                       0.0                      0.0                                0.0                            0.0                               1.0                     0.0                       0.0                0.0                     0.4601                   0.5399                    0.9899                  0.0101                      0.995539                    0.004461                                        0.044571                                      0.030984     0.000377                                         0.016866                                           0.030862                                                0.000165   \n",
            "..                 ...                                               ...                  ...                  ...                  ...                       ...                      ...                                ...                            ...                               ...                     ...                       ...                ...                        ...                      ...                       ...                     ...                           ...                         ...                                             ...                                           ...          ...                                              ...                                                ...                                                     ...   \n",
            "297                0.0                                               0.0                  0.0                  0.0                  0.0                       0.0                      0.0                                0.0                            0.0                               0.0                     1.0                       0.0                0.0                     0.1891                   0.8109                    0.5180                  0.4820                      0.518043                    0.481957                                        0.004571                                      0.000248     0.000277                                         0.000258                                           0.000248                                                0.000277   \n",
            "298                0.0                                               0.0                  0.0                  0.0                  0.0                       0.0                      0.0                                0.0                            0.0                               0.0                     1.0                       0.0                0.0                     1.0000                   0.0000                    0.3563                  0.6437                      0.356322                    0.643678                                        0.000000                                      0.000010     0.000026                                         0.000014                                           0.000010                                                0.000026   \n",
            "299                0.0                                               0.0                  0.0                  0.0                  0.0                       0.0                      0.0                                0.0                            0.0                               0.0                     1.0                       0.0                0.0                     0.3393                   0.6607                    0.3918                  0.6082                      0.423170                    0.576830                                        0.032000                                      0.001058     0.001963                                         0.000518                                           0.000405                                                0.000661   \n",
            "300                0.0                                               0.0                  0.0                  0.0                  0.0                       0.0                      0.0                                0.0                            0.0                               0.0                     1.0                       0.0                0.0                     0.3516                   0.6484                    0.3364                  0.6636                      0.336406                    0.663594                                        0.012571                                      0.000055     0.000133                                         0.000087                                           0.000055                                                0.000133   \n",
            "301                0.0                                               0.0                  0.0                  0.0                  0.0                       0.0                      0.0                                0.0                            0.0                               0.0                     1.0                       0.0                0.0                     0.1406                   0.8594                    0.4866                  0.5134                      0.486586                    0.513414                                        0.001143                                      0.000405     0.000512                                         0.000450                                           0.000405                                                0.000512   \n",
            "\n",
            "[302 rows x 25 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# define inputs and outputs\n",
        "# exclude_columns = [\n",
        "#     'Percentage Women Reports',\n",
        "#     'Percentage Men Reports',\n",
        "#     'Proportion of females in most relevant studies',\n",
        "#     'Proportion of males in most relevant studies',\n",
        "#     'Female proportion in studies',\n",
        "#     'Male proportion in studies',\n",
        "#     'Prevalence Men',\n",
        "#     'Prevalence Women',\n",
        "#     'Prevalence Both Genders',\n",
        "# ]\n",
        "# X = transformed_df.drop(columns=exclude_columns)\n",
        "X = transformed_df[[\n",
        "            'Indication_ASTHMA',\n",
        "             'Indication_CHRONIC OBSTRUCTIVE PULMONARY DISEASE',\n",
        "             'Indication_DEMENTIA',\n",
        "             'Indication_DIABETES',\n",
        "             'Indication_EPILEPSY',\n",
        "             'Indication_HEART FAILURE',\n",
        "             'Indication_HYPERTENSION',\n",
        "             'Indication_ISCHEMIC HEART DISEASE',\n",
        "             'Indication_MULTIPLE SCLEROSIS',\n",
        "             'Indication_MYOCARDIAL INFARCTION',\n",
        "             \"Indication_PARKINSON'S\",\n",
        "             'Indication_SCHIZOPHRENIA',\n",
        "             'Indication_STROKE',\n",
        "            'Total females in studies',\n",
        "            'Total males in studies',\n",
        "            'Num Studies',\n",
        "            'Number of participants in most relevant studies',\n",
        "            'Number of female participants in most relevant studies',\n",
        "            'Number of male participants in most relevant studies',\n",
        "            ]]\n",
        "\n",
        "y = transformed_df[\"Percentage Female Reports\"]\n",
        "\n",
        "# divide into test, train, val\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n"
      ],
      "metadata": {
        "id": "oApHNEcXt_ex"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# define model\n",
        "model = RandomForestRegressor(random_state=42)\n",
        "# model = tree.DecisionTreeRegressor(random_state=42)\n",
        "# model = linear_model.LinearRegression()\n",
        "# model = Ridge(random_state=42)\n",
        "# model = Lasso(random_state=42)\n",
        "# model = lgb.LGBMRegressor(random_state=42)\n",
        "# model = SGDRegressor(random_state=42)\n",
        "# kernel = C(1.0, (1e-4, 1e1)) * RBF(1.0, (1e-4, 1e1))\n",
        "# model = GaussianProcessRegressor(kernel=kernel, n_restarts_optimizer=15, random_state=42)\n",
        "# model = HistGradientBoostingRegressor(random_state=42)"
      ],
      "metadata": {
        "id": "DauzHLo81HcL"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# parameter tuning\n",
        "# random forest params\n",
        "param_grid = {\n",
        "    'n_estimators': [50, 100, 200],\n",
        "    'max_depth': [None, 10, 20, 30],\n",
        "    'min_samples_split': [2, 5, 10],\n",
        "    'min_samples_leaf': [1, 2, 4],\n",
        "    'max_features': ['auto', 'sqrt', 'log2'],\n",
        "    'bootstrap': [True, False]\n",
        "}\n",
        "\n",
        "# grid search\n",
        "grid_search = GridSearchCV(estimator=model, param_grid=param_grid, cv=5, n_jobs=-1, verbose=2, scoring='neg_mean_squared_error')\n",
        "grid_search.fit(X_train, y_train)\n",
        "best_model = grid_search.best_estimator_"
      ],
      "metadata": {
        "id": "C3wKQaYLDj2-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0b3c495d-316f-4ba5-e2cb-b7ae19af7987"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 5 folds for each of 648 candidates, totalling 3240 fits\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py:540: FitFailedWarning: \n",
            "1080 fits failed out of a total of 3240.\n",
            "The score on these train-test partitions for these parameters will be set to nan.\n",
            "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
            "\n",
            "Below are more details about the failures:\n",
            "--------------------------------------------------------------------------------\n",
            "1080 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py\", line 888, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/base.py\", line 1466, in wrapper\n",
            "    estimator._validate_params()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/base.py\", line 666, in _validate_params\n",
            "    validate_parameter_constraints(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/utils/_param_validation.py\", line 95, in validate_parameter_constraints\n",
            "    raise InvalidParameterError(\n",
            "sklearn.utils._param_validation.InvalidParameterError: The 'max_features' parameter of RandomForestRegressor must be an int in the range [1, inf), a float in the range (0.0, 1.0], a str among {'sqrt', 'log2'} or None. Got 'auto' instead.\n",
            "\n",
            "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_search.py:1052: UserWarning: One or more of the test scores are non-finite: [        nan         nan         nan         nan         nan         nan\n",
            "         nan         nan         nan         nan         nan         nan\n",
            "         nan         nan         nan         nan         nan         nan\n",
            "         nan         nan         nan         nan         nan         nan\n",
            "         nan         nan         nan -0.07475715 -0.07633107 -0.07579165\n",
            " -0.07070557 -0.07125977 -0.07137724 -0.06760936 -0.0690621  -0.06897066\n",
            " -0.07125931 -0.07181734 -0.07164872 -0.07050246 -0.07101457 -0.07082374\n",
            " -0.06930938 -0.06979823 -0.06926956 -0.06768689 -0.06826553 -0.06799318\n",
            " -0.06768689 -0.06826553 -0.06799318 -0.06851352 -0.06846929 -0.06767785\n",
            " -0.07475715 -0.07633107 -0.07579165 -0.07070557 -0.07125977 -0.07137724\n",
            " -0.06760936 -0.0690621  -0.06897066 -0.07125931 -0.07181734 -0.07164872\n",
            " -0.07050246 -0.07101457 -0.07082374 -0.06930938 -0.06979823 -0.06926956\n",
            " -0.06768689 -0.06826553 -0.06799318 -0.06768689 -0.06826553 -0.06799318\n",
            " -0.06851352 -0.06846929 -0.06767785         nan         nan         nan\n",
            "         nan         nan         nan         nan         nan         nan\n",
            "         nan         nan         nan         nan         nan         nan\n",
            "         nan         nan         nan         nan         nan         nan\n",
            "         nan         nan         nan         nan         nan         nan\n",
            " -0.07125886 -0.07242826 -0.07262828 -0.07159117 -0.07131408 -0.07087858\n",
            " -0.06730541 -0.06871556 -0.0686003  -0.07128383 -0.07202019 -0.07144734\n",
            " -0.0703393  -0.07031249 -0.06994943 -0.06886074 -0.06945296 -0.06892594\n",
            " -0.06760127 -0.06813106 -0.06781519 -0.06760127 -0.06813106 -0.06781519\n",
            " -0.06840301 -0.06848354 -0.06762127 -0.07125886 -0.07242826 -0.07262828\n",
            " -0.07159117 -0.07131408 -0.07087858 -0.06730541 -0.06871556 -0.0686003\n",
            " -0.07128383 -0.07202019 -0.07144734 -0.0703393  -0.07031249 -0.06994943\n",
            " -0.06886074 -0.06945296 -0.06892594 -0.06760127 -0.06813106 -0.06781519\n",
            " -0.06760127 -0.06813106 -0.06781519 -0.06840301 -0.06848354 -0.06762127\n",
            "         nan         nan         nan         nan         nan         nan\n",
            "         nan         nan         nan         nan         nan         nan\n",
            "         nan         nan         nan         nan         nan         nan\n",
            "         nan         nan         nan         nan         nan         nan\n",
            "         nan         nan         nan -0.07471202 -0.0761998  -0.07586276\n",
            " -0.07071668 -0.07126816 -0.0713673  -0.06760936 -0.0690621  -0.06897066\n",
            " -0.07125931 -0.07181129 -0.071634   -0.07050246 -0.07101457 -0.07082374\n",
            " -0.06930938 -0.06979823 -0.06926956 -0.06768689 -0.06826553 -0.06799318\n",
            " -0.06768689 -0.06826553 -0.06799318 -0.06851352 -0.06846929 -0.06767785\n",
            " -0.07471202 -0.0761998  -0.07586276 -0.07071668 -0.07126816 -0.0713673\n",
            " -0.06760936 -0.0690621  -0.06897066 -0.07125931 -0.07181129 -0.071634\n",
            " -0.07050246 -0.07101457 -0.07082374 -0.06930938 -0.06979823 -0.06926956\n",
            " -0.06768689 -0.06826553 -0.06799318 -0.06768689 -0.06826553 -0.06799318\n",
            " -0.06851352 -0.06846929 -0.06767785         nan         nan         nan\n",
            "         nan         nan         nan         nan         nan         nan\n",
            "         nan         nan         nan         nan         nan         nan\n",
            "         nan         nan         nan         nan         nan         nan\n",
            "         nan         nan         nan         nan         nan         nan\n",
            " -0.07475715 -0.07633107 -0.07579165 -0.07070557 -0.07125977 -0.07137724\n",
            " -0.06760936 -0.0690621  -0.06897066 -0.07125931 -0.07181734 -0.07164872\n",
            " -0.07050246 -0.07101457 -0.07082374 -0.06930938 -0.06979823 -0.06926956\n",
            " -0.06768689 -0.06826553 -0.06799318 -0.06768689 -0.06826553 -0.06799318\n",
            " -0.06851352 -0.06846929 -0.06767785 -0.07475715 -0.07633107 -0.07579165\n",
            " -0.07070557 -0.07125977 -0.07137724 -0.06760936 -0.0690621  -0.06897066\n",
            " -0.07125931 -0.07181734 -0.07164872 -0.07050246 -0.07101457 -0.07082374\n",
            " -0.06930938 -0.06979823 -0.06926956 -0.06768689 -0.06826553 -0.06799318\n",
            " -0.06768689 -0.06826553 -0.06799318 -0.06851352 -0.06846929 -0.06767785\n",
            "         nan         nan         nan         nan         nan         nan\n",
            "         nan         nan         nan         nan         nan         nan\n",
            "         nan         nan         nan         nan         nan         nan\n",
            "         nan         nan         nan         nan         nan         nan\n",
            "         nan         nan         nan -0.08633983 -0.08616304 -0.08571521\n",
            " -0.07965544 -0.08011082 -0.07987397 -0.07426492 -0.07429926 -0.0742978\n",
            " -0.08031993 -0.07865165 -0.07861818 -0.07761905 -0.0770616  -0.07733738\n",
            " -0.07331621 -0.07310143 -0.07379629 -0.07266412 -0.07258309 -0.07245693\n",
            " -0.07266412 -0.07258309 -0.07245693 -0.07158369 -0.07212459 -0.07121343\n",
            " -0.08633983 -0.08616304 -0.08571521 -0.07965544 -0.08011082 -0.07987397\n",
            " -0.07426492 -0.07429926 -0.0742978  -0.08031993 -0.07865165 -0.07861818\n",
            " -0.07761905 -0.0770616  -0.07733738 -0.07331621 -0.07310143 -0.07379629\n",
            " -0.07266412 -0.07258309 -0.07245693 -0.07266412 -0.07258309 -0.07245693\n",
            " -0.07158369 -0.07212459 -0.07121343         nan         nan         nan\n",
            "         nan         nan         nan         nan         nan         nan\n",
            "         nan         nan         nan         nan         nan         nan\n",
            "         nan         nan         nan         nan         nan         nan\n",
            "         nan         nan         nan         nan         nan         nan\n",
            " -0.07856919 -0.07912774 -0.07913413 -0.07712904 -0.07640701 -0.07636169\n",
            " -0.07217768 -0.07242498 -0.07249302 -0.0780346  -0.07672217 -0.07648966\n",
            " -0.07590318 -0.07498499 -0.07509657 -0.07210055 -0.07187948 -0.07269296\n",
            " -0.07242607 -0.07204178 -0.07176225 -0.07242607 -0.07204178 -0.07176225\n",
            " -0.07135311 -0.0714378  -0.07103102 -0.07856919 -0.07912774 -0.07913413\n",
            " -0.07712904 -0.07640701 -0.07636169 -0.07217768 -0.07242498 -0.07249302\n",
            " -0.0780346  -0.07672217 -0.07648966 -0.07590318 -0.07498499 -0.07509657\n",
            " -0.07210055 -0.07187948 -0.07269296 -0.07242607 -0.07204178 -0.07176225\n",
            " -0.07242607 -0.07204178 -0.07176225 -0.07135311 -0.0714378  -0.07103102\n",
            "         nan         nan         nan         nan         nan         nan\n",
            "         nan         nan         nan         nan         nan         nan\n",
            "         nan         nan         nan         nan         nan         nan\n",
            "         nan         nan         nan         nan         nan         nan\n",
            "         nan         nan         nan -0.08686242 -0.08665866 -0.08620569\n",
            " -0.07958977 -0.0800109  -0.07985315 -0.07431454 -0.0743276  -0.07424739\n",
            " -0.08041567 -0.07866484 -0.07860142 -0.0774145  -0.07692548 -0.07728122\n",
            " -0.07331038 -0.07309862 -0.07379491 -0.07266412 -0.07258309 -0.07245693\n",
            " -0.07266412 -0.07258309 -0.07245693 -0.07158369 -0.07212459 -0.07121343\n",
            " -0.08686242 -0.08665866 -0.08620569 -0.07958977 -0.0800109  -0.07985315\n",
            " -0.07431454 -0.0743276  -0.07424739 -0.08041567 -0.07866484 -0.07860142\n",
            " -0.0774145  -0.07692548 -0.07728122 -0.07331038 -0.07309862 -0.07379491\n",
            " -0.07266412 -0.07258309 -0.07245693 -0.07266412 -0.07258309 -0.07245693\n",
            " -0.07158369 -0.07212459 -0.07121343         nan         nan         nan\n",
            "         nan         nan         nan         nan         nan         nan\n",
            "         nan         nan         nan         nan         nan         nan\n",
            "         nan         nan         nan         nan         nan         nan\n",
            "         nan         nan         nan         nan         nan         nan\n",
            " -0.08633983 -0.08616304 -0.08571521 -0.07965544 -0.08011082 -0.07987397\n",
            " -0.07426492 -0.07429926 -0.0742978  -0.08031993 -0.07865165 -0.07861818\n",
            " -0.07761905 -0.0770616  -0.07733738 -0.07331621 -0.07310143 -0.07379629\n",
            " -0.07266412 -0.07258309 -0.07245693 -0.07266412 -0.07258309 -0.07245693\n",
            " -0.07158369 -0.07212459 -0.07121343 -0.08633983 -0.08616304 -0.08571521\n",
            " -0.07965544 -0.08011082 -0.07987397 -0.07426492 -0.07429926 -0.0742978\n",
            " -0.08031993 -0.07865165 -0.07861818 -0.07761905 -0.0770616  -0.07733738\n",
            " -0.07331621 -0.07310143 -0.07379629 -0.07266412 -0.07258309 -0.07245693\n",
            " -0.07266412 -0.07258309 -0.07245693 -0.07158369 -0.07212459 -0.07121343]\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Baseline model prediction\n",
        "# Calculate the mean of the target variable in the training set\n",
        "n_samples = len(y_test)\n",
        "mean_target = np.mean(y_train)\n",
        "\n",
        "# Mean predictions (same value for all instances)\n",
        "mean_predictions = np.full(n_samples, mean_target)\n",
        "\n",
        "# Calculate MAE and MSE for the mean predictor\n",
        "mean_mae = mean_absolute_error(y_test, mean_predictions)\n",
        "mean_mse = mean_squared_error(y_test, mean_predictions)\n",
        "\n",
        "print(f'Mean Predictor - MAE: {mean_mae}')\n",
        "print(f'Mean Predictor - MSE: {mean_mse}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ipKeYP_gnvfF",
        "outputId": "e7e2bf2c-22ca-4640-91ae-3d14fb018ebe"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mean Predictor - MAE: 0.21552510033331063\n",
            "Mean Predictor - MSE: 0.07107030916294399\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# test set\n",
        "y_test_pred = best_model.predict(X_test)\n",
        "\n",
        "# evaluate performance\n",
        "test_mae = mean_absolute_error(y_test, y_test_pred)\n",
        "test_mse = mean_squared_error(y_test, y_test_pred)\n",
        "test_r2 = r2_score(y_test, y_test_pred)\n",
        "\n",
        "\n",
        "print(f'Test MAE: {test_mae}')\n",
        "print(f'Test MSE: {test_mse}')\n",
        "print(f'Test R2: {test_r2}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1X2O6Y6d3-Zo",
        "outputId": "2d4c8558-ca23-417a-91b3-e39fe95e7160"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test MAE: 0.19926457259495706\n",
            "Test MSE: 0.07280708885923162\n",
            "Test R2: -0.027902609723094995\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# save model with pickle\n",
        "save_path = '/content/drive/My Drive/Models/'\n",
        "\n",
        "# Save the best model and preprocessor\n",
        "with open(save_path + 'regression_model.pkl', 'wb') as f:\n",
        "    pickle.dump(best_model, f)\n",
        "\n",
        "with open(save_path + 'preprocessor.pkl', 'wb') as f:\n",
        "    pickle.dump(preprocessor, f)"
      ],
      "metadata": {
        "id": "SoqiOAU1qTxN"
      },
      "execution_count": 15,
      "outputs": []
    }
  ]
}